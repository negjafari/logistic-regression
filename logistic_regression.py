# -*- coding: utf-8 -*-
"""logistic regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rXYA2Ueddu3fh4y5TXucHxm5n64-9cQA

Import essential libraries
"""

from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import time

drive.mount('/content/drive')

dataset_path1 = '/content/drive/MyDrive/logistic regression dataset/breast_cancer_modified.csv'
df1 = pd.read_csv(dataset_path1)

dataset_path2 = '/content/drive/MyDrive/logistic regression dataset/ionosphere_modified.csv'
df2 = pd.read_csv(dataset_path2)

"""# Dataset Analysis"""

pd.set_option('display.max_columns', None)  # Set to None to display all columns

def check_missing_values(df):
    missing_values = df.isnull().sum()
    return missing_values

missing_values_df1 = check_missing_values(df1)
print("Missing values in each column:")
print(missing_values_df1)

missing_values_df2 = check_missing_values(df2)
print("Missing values in each column:")
print(missing_values_df2)

df1.describe()

df2.describe()

df1 = df1.drop(columns=['ID'])
df2 = df2.drop(columns=['Feature_2'])

# Distribution of classes
print(df1['Diagnosis'].value_counts())
print(df2['Label'].value_counts())

# Class distribution for Breast Cancer dataset
sns.countplot(x='Diagnosis', data=df1)
plt.title('Distribution of Classes in Breast Cancer Dataset')
plt.show()

# Class distribution for Ionosphere dataset
sns.countplot(x='Label', data=df2)
plt.title('Distribution of Classes in Ionosphere Dataset')
plt.show()

def feature_distribution(df, name):
  features_io = df.columns[:-1]
  for feature in features_io:
      sns.histplot(df[feature], kde=True)
      plt.title(f'Distribution of {feature} - {name}')
      plt.show()

feature_distribution(df1, 'Breast Cancer')

feature_distribution(df2, 'Ionosphere')

def visualize_correlation_matrix(df, title):
    corr_matrix = df.corr()
    # Mask to hide upper triangle
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

    f, ax = plt.subplots(figsize=(11, 9))

    cmap = sns.diverging_palette(230, 20, as_cmap=True)


    sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,
                square=True, linewidths=.5, cbar_kws={"shrink": .5},
                annot=False)  # Annotations are turned off for clarity
    plt.title(title)
    plt.show()

visualize_correlation_matrix(df1, 'Full Correlation Matrix for Breast Cancer Dataset')

visualize_correlation_matrix(df2, 'Full Correlation Matrix for Ionosphere Dataset')

"""# Preprocessing

Encode categorical variables
"""

df1['Diagnosis'] = df1['Diagnosis'].map({'B': 1, 'M': 0})
df2['Label'] = df2['Label'].map({'g': 1, 'b': 0})

# select all features except the target
features_bc = df1.columns[:-1]
features_io = df2.columns[:-1]

def normalize_features(df, feature_names):
    for feature in feature_names:
        min_value = df[feature].min()
        max_value = df[feature].max()
        df[feature] = (df[feature] - min_value) / (max_value - min_value)

# Choose a feature for demonstration
feature = features_bc[5]  # Replace with the actual feature name you are interested in

# Store a copy of the original feature values
original_feature_values = df1[feature].copy()

# Normalize the feature without altering the original dataframe
normalized_feature_values = (df1[feature] - df1[feature].min()) / (df1[feature].max() - df1[feature].min())

# Histogram comparison
plt.figure(figsize=(14, 6))

# Original feature histogram
plt.subplot(1, 2, 1)
sns.histplot(original_feature_values, kde=True, color="blue")
plt.title(f'Distribution of {feature} Before Normalization')
plt.xlabel(f'{feature} Value')
plt.ylabel('Frequency')

# Normalized feature histogram
plt.subplot(1, 2, 2)
sns.histplot(normalized_feature_values, kde=True, color="green")
plt.title(f'Distribution of {feature} After Normalization')
plt.xlabel(f'{feature} Value')
plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

normalize_features(df1, features_bc)

df1.describe()

"""# Feature Selection"""

# Compute the correlation matrix
correlation_matrix1 = df1.corr()

# Isolate the correlations with the label
label_correlations1 = correlation_matrix1['Diagnosis'].drop('Diagnosis')

# Sort the correlations
sorted_correlations1 = label_correlations1.sort_values(ascending=False)

print("Sorted correlations:")
print(sorted_correlations1)

# Select features with correlation greater than 0.5
top_features = sorted_correlations1[sorted_correlations1 > 0.5].index.tolist()

# Select features with correlation less than -0.5
bottom_features = sorted_correlations1[sorted_correlations1 < -0.75].index.tolist()

print("Top Features:\n", top_features)
print("Bottom Features:\n", bottom_features)


for feature in top_features:
    # Square the feature and normalize
    df1[feature + '_squared'] = df1[feature] ** 2
    # Normalize the squared feature
    min_value = df1[feature + '_squared'].min()
    max_value = df1[feature + '_squared'].max()
    df1[feature + '_squared'] = (df1[feature + '_squared'] - min_value) / (max_value - min_value)


epsilon = 1e-6  # A small constant to prevent division by zero

for feature in bottom_features:
    # Inverse the feature with epsilon to prevent division by zero or very large values
    df1[feature + '_inverse'] = 1 / (df1[feature] + epsilon)

    # Normalize the inverse feature
    min_value = df1[feature + '_inverse'].min()
    max_value = df1[feature + '_inverse'].max()
    df1[feature + '_inverse'] = (df1[feature + '_inverse'] - min_value) / (max_value - min_value)

df1.columns

df1.describe()

# Compute the correlation matrix
correlation_matrix2 = df2.corr()

# Isolate the correlations with the label
label_correlations2 = correlation_matrix2['Label'].drop('Label')

# Sort the correlations
sorted_correlations2 = label_correlations2.sort_values(ascending=False)

print("Sorted correlations:")
print(sorted_correlations2)

# Select features with correlation greater than 0.5
top_features = sorted_correlations2[sorted_correlations2 > 0.5].index.tolist()

# Select features with correlation less than -0.5
bottom_features = sorted_correlations2[sorted_correlations2 < -0.5].index.tolist()

print("Top Features:\n", top_features)
print("Bottom Features:\n", bottom_features)

# Applying the operations for top_features
for feature in top_features:
    # Square the feature and normalize
    df2[feature + '_squared'] = df2[feature] ** 2
    df2[feature + '_squared'] = (df2[feature + '_squared'] - df2[feature + '_squared'].mean()) / df2[feature + '_squared'].std()
    min_value = df2[feature + '_squared'].min()
    max_value = df2[feature + '_squared'].max()
    df2[feature + '_squared'] = (df2[feature + '_squared'] - min_value) / (max_value - min_value)

# Applying the operations for bottom_features
for feature in bottom_features:
    # Inverse the feature and normalize
    df2[feature + '_inverse'] = 1 / df2[feature]
    df2[feature + '_inverse'] = (df2[feature + '_inverse'] - df2[feature + '_inverse'].mean()) / df2[feature + '_inverse'].std()
    min_value = df2[feature + '_inverse'].min()
    max_value = df2[feature + '_inverse'].max()
    df2[feature + '_inverse'] = (df2[feature + '_inverse'] - min_value) / (max_value - min_value)

df2.columns

df2.describe()

"""# Logistic Regression"""

def train_test_split(X, y, test_size=0.2):

    np.random.seed(42)  # Fixed seed for reproducibility

    # Concatenate X and y to shuffle them together
    full_dataset = np.concatenate((X, y.reshape(-1, 1)), axis=1)
    np.random.shuffle(full_dataset)

    train_size = int(full_dataset.shape[0] * (1 - test_size))

    train, test = full_dataset[:train_size], full_dataset[train_size:]

    X_train = train[:, :-1]
    y_train = train[:, -1]
    X_test = test[:, :-1]
    y_test = test[:, -1]

    return X_train, X_test, y_train, y_test

class LogisticRegression:
    def __init__(self, learning_rate, iterations=1000):
        self.learning_rate = learning_rate
        self.iterations = iterations
        self.weights = None
        self.bias = None

    def _sigmoid(self, z):
        # Clip values to avoid overflow in the exponential
        z = np.clip(z, -500, 500)
        return 1 / (1 + np.exp(-z))

    def _compute_loss(self, y, y_hat):
        m = y.shape[0]
        # Clip predictions to avoid log(0)
        y_hat = np.clip(y_hat, 1e-9, 1 - 1e-9)
        loss = -np.mean(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))
        return loss

    def fit(self, X, y):
        n_samples, n_features = X.shape
        self.weights = np.zeros(n_features)
        self.bias = 0

        # Gradient Descent
        for i in range(self.iterations):
            model = np.dot(X, self.weights) + self.bias
            predictions = self._sigmoid(model)

            # Compute gradients
            dw = (1 / n_samples) * np.dot(X.T, (predictions - y))
            db = (1 / n_samples) * np.sum(predictions - y)

            # Update parameters
            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db

            # Calculate and print the loss every 100 iterations
            if (i + 1) % 100 == 0:
                loss = self._compute_loss(y, predictions)
                print(f"Iteration {i + 1}, Loss: {loss:.4f}")

    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]
        return np.array(y_predicted_cls)

def accu_eval(predicted_labels, true_labels):
    correct_predictions = np.sum(predicted_labels == true_labels)
    total_predictions = len(true_labels)
    accuracy = correct_predictions / total_predictions
    return accuracy

class KFoldCrossValidation:
    def __init__(self, model, k=10):
        self.k = k
        self.model = model

    def _create_folds(self, X, y):
        m = len(y)
        fold_sizes = np.full(self.k, m // self.k, dtype=int)
        fold_sizes[:m % self.k] += 1
        current = 0
        folds = []
        for fold_size in fold_sizes:
            start, stop = current, current + fold_size
            folds.append((start, stop))
            current = stop
        return folds

    def cross_validate(self, X, y):
        folds = self._create_folds(X, y)
        accuracies = []

        for start, stop in folds:
            train_indices = list(range(0, start)) + list(range(stop, len(y)))
            test_indices = list(range(start, stop))

            X_train, y_train = X[train_indices], y[train_indices]
            X_test, y_test = X[test_indices], y[test_indices]

            self.model.fit(X_train, y_train)
            predictions = self.model.predict(X_test)
            accuracy = accu_eval(predictions, y_test)
            accuracies.append(accuracy)

        return np.mean(accuracies), accuracies

learning_rates = [0.001, 0.01, 0.1, 1]

model = LogisticRegression(learning_rate=1, iterations=1000)

X = df1.drop('Diagnosis', axis=1).values
y = df1['Diagnosis'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
print("x train shape: ", X_train.shape)
print("y train shape: ", y_train.shape)
print("x test shape: ", X_test.shape)
print("y test shape: ", y_test.shape)

start_time = time.time()

model.fit(X_train, y_train)
predictions = model.predict(X_test)

end_time = time.time()

runtime = end_time - start_time

accuracy = accu_eval(predictions, y_test)
print(f"Accuracy of the logistic regression model: {accuracy:.4f}")
print(f"Training Time: {runtime:.3f} seconds")

cross_validator = KFoldCrossValidation(model, k=10)

mean_accuracy, fold_accuracies = cross_validator.cross_validate(X, y)

print(f"Mean accuracy over {cross_validator.k} folds: {mean_accuracy}")
print(f"Accuracies over each fold: {fold_accuracies}")

"""second dataset"""

X = df2.drop('Label', axis=1).values
y = df2['Label'].values

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
print("x train shape: ", X_train.shape)
print("y train shape: ", y_train.shape)
print("x test shape: ", X_test.shape)
print("y test shape: ", y_test.shape)

start_time = time.time()

model.fit(X_train, y_train)
predictions = model.predict(X_test)

end_time = time.time()

runtime = end_time - start_time

accuracy = accu_eval(predictions, y_test)
print(f"Accuracy of the logistic regression model: {accuracy:.4f}")
print(f"Training Time: {runtime:.3f} seconds")

cross_validator = KFoldCrossValidation(model, k=10)

mean_accuracy, fold_accuracies = cross_validator.cross_validate(X, y)

print(f"Mean accuracy over {cross_validator.k} folds: {mean_accuracy}")
print(f"Accuracies over each fold: {fold_accuracies}")

